{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolution is simply a filter of weights that are used to multiply a pixel with its neighbors to get a new value for the pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577.0\n"
     ]
    }
   ],
   "source": [
    "new_val = (-1*0)+(0*64)+(-2*128) + (.5*48)+(4.5*192)+(-1.5*144)+ (1.5*142)+(2*226)+(-3*168)\n",
    "print(new_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling is the process of eliminating pixels in your image while maintaining the semantics of the content within the image. To implement a convolutional layer, you’ll use the tf.keras.layers.Conv2D type. This accepts as parameters the number of convolutions to use in the layer, the size of the convolutions, the activation function, etc.\n",
    "#tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                input_shape=(28, 28, 1))\n",
    "We want the layer to learn 64 convolutions. It will randomly initialize these, and over time will learn the filter values that work best to match the input val‐ ues to their labels. The (3, 3) indicates the size of the filter. This is the most common size of filter; you can change it as you see fit, but you’ll typically see an odd number of axes like 5 × 5 or 7 × 7 because of how filters remove pixels from the borders of the image, as you’ll see later. The activation and input_shape parameters are the same as before. As we’re using Fashion MNIST in this example, the shape is still 28 × 28. Because Conv2D layers are designed for multicolor images, we’re specifying the third dimension as 1, so our input shape is 28 × 28 × 1. Color images will typically have a 3 as the third parameter as they are stored as values of R, G, and B.\n",
    "Here’s how to use a pooling layer in the neural network. You’ll typically do this imme‐ diately after the convolutional layer:\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "In the example in Figure 3-4, we split the image into 2 × 2 pools and picked the maxi‐ mum value in each. This operation could have been parameterized to define the pool size. Those are the parameters that you can see here—the (2, 2) indicates that our pools are 2 × 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "data = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
