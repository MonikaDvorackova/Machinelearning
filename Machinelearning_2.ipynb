{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 16:45:20.217148: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-10-09 16:45:20.293528: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.5466 - accuracy: 0.8102\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.4696 - accuracy: 0.8370\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.4667 - accuracy: 0.8399\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4652 - accuracy: 0.8408\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.4719 - accuracy: 0.8429\n",
      "  9/313 [..............................] - ETA: 2s - loss: 0.4447 - accuracy: 0.8368  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 16:46:31.789859: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5225 - accuracy: 0.8208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5225253701210022, 0.8208000659942627]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = data.load_data()\n",
    "\n",
    "#operation across the entire array like this, all of the pixels in our gray image scale are with values between 0 and 255, dividing by 255 thus ensures that every pixel is represented by a number between 0 and 1 instead -> normalizing the images\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "#first flatten is the layer specification\n",
    "# input 28 x 28 images -. series of values\n",
    "# flatten takes the square value (2D array) and turns it into a line (a 1D array)\n",
    "#dense is the layer of neuron - 128 - middle, hidden layer, no fixed rule for the neurons to use\n",
    "# more neurons more slowly\n",
    "# more neurons leads to recognizing training data greatly, but not the data it has not already seen -> overfitting \n",
    "#hyperparametr tuning - value, that is used to control the training - opposed to the internal values of the neurons that get trained (parameters)\n",
    "#activation function - code that will execute on each neuron, function that returns a value if its greater than 0, we dont want negative values to being passed to the next layer -> activate the layer with relu\n",
    "#10 neurons because of 10 classes\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "    tf.keras.layers.Dense(10, activation= tf.nn.softmax)\n",
    "])\n",
    "\n",
    "#specify the loss function and the optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification gives us back an array of values. These are the val‐ ues of the 10 output neurons. The label is the actual label for the item of clothing, in this case 9. There’s a 91.4% chance that the item of clothing at index 0 is label 9. We know that it’s label 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "[2.1100830e-08 6.9072963e-11 6.5779091e-07 1.2020794e-08 5.7153418e-08\n",
      " 6.7010261e-02 1.1357068e-06 2.1120697e-02 1.5411586e-04 9.1171306e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting -> 50 epochs instead of 5 - accuracy will be bigger, but the test set will be 88 %. It has become overspecialized to the training data, a process often called overfitting. The network is doing much better with the training data, but it’s not necessarily a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks - we might want to train until we reach the desired accuracy instead of constantly trying different numbers of epochs and training and retraining until we get to our desired value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 17:07:28.283036: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-10-09 17:07:28.342176: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.5477 - accuracy: 0.8100\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4715 - accuracy: 0.8377\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4685 - accuracy: 0.8390\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4708 - accuracy: 0.8395\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4759 - accuracy: 0.8382\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.4741 - accuracy: 0.8411\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.4821 - accuracy: 0.8397\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4931 - accuracy: 0.8373\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4945 - accuracy: 0.8373\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.5060 - accuracy: 0.8372\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.5107 - accuracy: 0.8351\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.5135 - accuracy: 0.8360\n",
      "Epoch 13/50\n",
      " 658/1875 [=========>....................] - ETA: 9s - loss: 0.5062 - accuracy: 0.8371"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#class called myCallback, that takes a tf.keras.callbacks.callback as a parameter\n",
    "#in it we define on_epoch_end function, which will give us details about the logs for this epoch. In these logs is an accuracy value, so all we have to do is see if it is greater than .95 (or 95%); if it is, we can stop training by saying self.model.stop_training = True\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.95):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics= ['accuracy'])\n",
    "\n",
    "#to train for 50 epochs, and then added a callbacks parameter. To this, I pass the callbacks object. When training, at the end of every epoch, the callback function will be called.\n",
    "model.fit(training_images, training_labels, epochs = 50, callbacks = [callbacks])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
